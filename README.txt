Nguyen Van Quoc Chuong 
47787810
INFS4205

Because of the large size of datasets, so I put the those google drive links here:

- This csv file contains the invalid indecies when doing the preprocessing that finds the invalid trips:
https://drive.google.com/file/d/10INOCswjeU0ORSFajo6Wdhw_SNejJtI_/view?usp=sharing  


- Google collab file for that step:
https://colab.research.google.com/drive/1DO1FKAj07cQQ4FlAQGnupIy59jVLkWC2


- The csv dataset file after doing preprocessing: (3.54gb)
https://drive.google.com/file/d/12nOcw5q7i_7daxMgGo1NbNV_FLcKbpG6/view?usp=share_link

- The final dataset (cropped down to 999998 rows) I used to do queries:
https://drive.google.com/file/d/1Q_bkHMXmafNm9WRW7KS7_CAJQgtWwvLe/view?usp=share_link


- Other necessary files are included in zip file.


For task 4, 5 I didn't run the postgreSQL script because it's tooooo slow.
I sure that result is same as linear scan, and time execution is longggggg tooo.
 